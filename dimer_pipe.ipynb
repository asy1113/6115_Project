{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dimer pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "unid = 'u0496358'\n",
    "path = \"/home/\"+str(unid)+\"/BRAT/\"+str(unid)+\"/Project_pe_test\" \n",
    "files = os.listdir(path)\n",
    "\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    " \n",
    "rule=r'(?P<name>(d-dimer|ddimer))(?P<n1>.{1,25}?)(?P<value>[0-9]{1,4}(\\.[0-9]{0,3})?\\s*)(?P<n2>[^\\n\\w\\d]*)(?P<unit>(ug\\/l|ng\\/ml|mg\\/l|nmol\\/l)?)'\n",
    "rule1=r'(elevated|pos|positive|increased|high|\\+)(.{1,20})?(\\n)?\\s?(d-dimer|d\\s?dimer)'  \n",
    "rule2=r'(d-dimer|d\\s?dimer)([^0-9-:]{1,15})?(positive|pos)'\n",
    "neg_regex = '(\\\\bno\\\\b|denies)'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d-dimer pipeline apply rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddimer_val(rule='rule', rule1='rule1', rule2='rule2', file_txt='note'):\n",
    "\n",
    "    # import libraries\n",
    "    import re\n",
    "    from pipeUtils import Annotation\n",
    "    from pipeUtils import Document\n",
    "\n",
    "    # initite Document obj\n",
    "    file1a = ''\n",
    "    doc = Document()\n",
    "    doc.load_document_from_file(file_txt)      \n",
    "\n",
    "    # change to lower case\n",
    "    doc.text = doc.text.lower()\n",
    "    \n",
    "#######################################################################################    \n",
    "# match name value unit in note e.g. d-dimer 123.456 ng/mL\n",
    "    \n",
    "    # for rule in rules: # different process, cannot repeat.\n",
    "    # compile and match in note text    \n",
    "    pattern=re.compile(rule)\n",
    "    matches=pattern.finditer(doc.text)   \n",
    "\n",
    "    ann_index=0\n",
    "    for match in matches:\n",
    "        ann_id = 'NLP_'+ str(ann_index)\n",
    "        ann_index=ann_index+1\n",
    "\n",
    "        # check value and unit, then nomalize value\n",
    "        if match.group('value') != None:\n",
    "            value = float(match.group('value')) # mg/L*1000, ug/L, ng/mL, nmol/L*186\n",
    "        if match.group('unit')=='mg/l':\n",
    "            value = value * 1000\n",
    "        if match.group('unit')=='nmol/l':\n",
    "            value = value * 186\n",
    "        # compare the value\n",
    "        if value < 500:\n",
    "            label = 'low_ddimer'   \n",
    "        else:\n",
    "            label = 'high_ddimer'    \n",
    "\n",
    "        # Add new annotation\n",
    "        new_annotation = Annotation(start_index=int(match.start()), \n",
    "                                end_index=int(match.end()), \n",
    "                                type=label,\n",
    "                                ann_id = ann_id\n",
    "                                )\n",
    "        new_annotation.spanned_text = doc.text[new_annotation.start_index:new_annotation.end_index]\n",
    "\n",
    "        # Check negation right before the found target up to 35 charachers before, \n",
    "        # making sure that the pre-text does not cross the text boundary and is valid\n",
    "        if new_annotation.start_index - 35 > 0:\n",
    "            pre_text_start = new_annotation.start_index - 35\n",
    "        else:\n",
    "            pre_text_start = 0\n",
    "\n",
    "        # ending index of the pre_text is the beginning of the found target    \n",
    "        pre_text_end = new_annotation.start_index    \n",
    "\n",
    "        # substring the document text to identify the pre_text string\n",
    "        pre_text = doc.text[pre_text_start: pre_text_end]\n",
    "\n",
    "        if value < 500:\n",
    "            new_annotation.attributes[\"Negation\"] ='Negated'\n",
    "        doc.annotations.append(new_annotation)\n",
    "        \n",
    "\n",
    "#######################################################################################\n",
    "# annotate Target 2: Modifier + Name\n",
    "\n",
    "    # compile and match in note text    \n",
    "    pattern1=re.compile(rule1)\n",
    "    matches1=pattern1.finditer(doc.text)  # match positive/+ d-dimer in note\n",
    "\n",
    "    for match1 in matches1:\n",
    "        ann_id = 'NLP_'+ str(ann_index)\n",
    "        ann_index=ann_index+1\n",
    "        new_annotation = Annotation(start_index=int(match1.start()), \n",
    "                                    end_index=int(match1.end()), \n",
    "                                    type='high_ddimer',\n",
    "                                    ann_id = ann_id\n",
    "                                    )\n",
    "        new_annotation.spanned_text = doc.text[new_annotation.start_index:new_annotation.end_index]\n",
    "\n",
    "        # Check negation right before the found target up to 30 charachers before, \n",
    "        # making sure that the pre-text does not cross the text boundary and is valid\n",
    "\n",
    "        if new_annotation.start_index - 30 > 0:\n",
    "            pre_text_start = new_annotation.start_index - 30\n",
    "        else:\n",
    "            pre_text_start = 0\n",
    "\n",
    "        # ending index of the pre_text is the beginning of the found target    \n",
    "        pre_text_end = new_annotation.start_index    \n",
    "\n",
    "        # substring the document text to identify the pre_text string\n",
    "        pre_text = doc.text[pre_text_start: pre_text_end]\n",
    "\n",
    "        # We do not need to know the exact location of the negation keyword, so re.search is acceptable\n",
    "        if re.search(neg_regex, pre_text , re.IGNORECASE):\n",
    "            new_annotation.attributes[\"Negation\"] ='Negated'\n",
    "        doc.annotations.append(new_annotation)\n",
    "        \n",
    "#######################################################################################\n",
    "# match d-dimer + positive in note\n",
    "\n",
    "    pattern2=re.compile(rule2)\n",
    "    matches2=pattern2.finditer(doc.text)  \n",
    "\n",
    "    for match2 in matches2:\n",
    "        ann_id = 'NLP_'+ str(ann_index)\n",
    "        ann_index=ann_index+1\n",
    "        new_annotation = Annotation(start_index=int(match2.start()), \n",
    "                                    end_index=int(match2.end()), \n",
    "                                    type='high_ddimer',\n",
    "                                    ann_id = ann_id\n",
    "                                    )\n",
    "        new_annotation.spanned_text = doc.text[new_annotation.start_index:new_annotation.end_index]\n",
    "\n",
    "        # Check negation right before the found target up to 30 charachers before, \n",
    "        # making sure that the pre-text does not cross the text boundary and is valid\n",
    "\n",
    "        if new_annotation.start_index - 30 > 0:\n",
    "            pre_text_start = new_annotation.start_index - 30\n",
    "        else:\n",
    "            pre_text_start = 0\n",
    "\n",
    "        # ending index of the pre_text is the beginning of the found target    \n",
    "        pre_text_end = new_annotation.start_index    \n",
    "\n",
    "        # substring the document text to identify the pre_text string\n",
    "        pre_text = doc.text[pre_text_start: pre_text_end]\n",
    "\n",
    "        # We do not need to know the exact location of the negation keyword, so re.search is acceptable\n",
    "        if re.search(neg_regex, pre_text , re.IGNORECASE):\n",
    "            new_annotation.attributes[\"Negation\"] ='Negated'\n",
    "        doc.annotations.append(new_annotation)\n",
    "        \n",
    "    return doc.annotations    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet\n",
    "\n",
    "doc_annotations=dict()\n",
    "\n",
    "note_count = 0                       # count the number of text notes want to process ***\n",
    "for i in files[:]:\n",
    "    if \".txt\" in i:\n",
    "        doc_file = os.path.join(path,i)\n",
    "        #note_count = note_count + 1  #\n",
    "        #if note_count > 2:           # count the number of text notes want to process ***\n",
    "        #    break                    #\n",
    "              \n",
    "        note_annotations = ddimer_val(rule=rule, rule1=rule1, rule2=rule2, file_txt=doc_file)\n",
    "\n",
    "        doc_annotations[i] = note_annotations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append annotation dataframes to annotation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for k in doc_annotations:               # dict of annotations\n",
    "      \n",
    "    k0=k.split('.')[0]\n",
    "    k1=k0+'.nlp'    \n",
    "\n",
    "    nlp_ann=''\n",
    "    for doc_ann in doc_annotations[k]:     # doc_ann is line of mention ann in doc annotation\n",
    "        \n",
    "        nlp_ann = nlp_ann + doc_ann.ann_id   +'\\t'  \n",
    "        nlp_ann = nlp_ann + doc_ann.type    +' '\n",
    "        nlp_ann = nlp_ann + str(doc_ann.start_index)   +' '\n",
    "        nlp_ann = nlp_ann + str(doc_ann.end_index)      +'\\t'\n",
    "        nlp_ann = nlp_ann + doc_ann.spanned_text    +'\\n'    \n",
    "\n",
    "    nlpann='nlpann/'+k1\n",
    "    with open(nlpann, 'a') as myfile:\n",
    "        myfile.write(nlp_ann)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doc classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90688_292.txt ----- high_ddimer\n",
      "65675_64.txt ----- high_ddimer\n",
      "48640_63.txt ----- low_ddimer\n",
      "86087_123.txt ----- high_ddimer\n",
      "83838_106.txt ----- high_ddimer\n",
      "72554_306.txt ----- high_ddimer\n",
      "15899_182.txt ----- high_ddimer\n",
      "13867_266.txt ----- high_ddimer\n",
      "61180_73.txt ----- high_ddimer\n",
      "32113_141.txt ----- high_ddimer\n",
      "59381_293.txt ----- high_ddimer\n",
      "58515_159.txt ----- high_ddimer\n",
      "6878_279.txt ----- high_ddimer\n",
      "820_14.txt ----- high_ddimer\n",
      "32113_109.txt ----- high_ddimer\n",
      "49079_68.txt ----- high_ddimer\n",
      "10568_20.txt ----- high_ddimer\n",
      "25764_268.txt ----- high_ddimer\n",
      "1498_225.txt ----- high_ddimer\n",
      "82326_55.txt ----- high_ddimer\n"
     ]
    }
   ],
   "source": [
    "\n",
    "doc_cls_results={}\n",
    "for k in doc_annotations:               # dict of annotations\n",
    "    doc_cls_results[k]='low_ddimer'\n",
    "    for doc_ann in doc_annotations[k]:\n",
    "        if doc_ann.type =='high_ddimer':\n",
    "            doc_cls_results[k]='high_ddimer'\n",
    "for k in doc_cls_results:\n",
    "    print(k, '-----', doc_cls_results[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select one doc annotation for mention level evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<pipeUtils.Annotation object at 0x7fa074ff0ef0>, <pipeUtils.Annotation object at 0x7fa074ebe7b8>]\n"
     ]
    }
   ],
   "source": [
    "k = '90688_292.txt'\n",
    "ann1 = doc_annotations[k]\n",
    "print(ann1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read annotation and convert to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>markup_id</th>\n",
       "      <th>type</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NLP_0</td>\n",
       "      <td>high_ddimer</td>\n",
       "      <td>398</td>\n",
       "      <td>414</td>\n",
       "      <td>elevated d-dimer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NLP_1</td>\n",
       "      <td>high_ddimer</td>\n",
       "      <td>2023</td>\n",
       "      <td>2039</td>\n",
       "      <td>elevated d-dimer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  markup_id         type  start   end               txt\n",
       "0     NLP_0  high_ddimer    398   414  elevated d-dimer\n",
       "1     NLP_1  high_ddimer   2023  2039  elevated d-dimer"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "nlp_list=[]\n",
    "for a in ann1:       \n",
    "    list1=[a.ann_id, a.type, a.start_index, a.end_index, a.spanned_text]\n",
    "    nlp_list.append(list1)\n",
    "nlp_list    \n",
    "\n",
    "nlp_df = pd.DataFrame(nlp_list, columns=['markup_id','type','start','end','txt'])    \n",
    "nlp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert df to annotation object, compare two annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df2ann(df=[], pdoc_type='', ndoc_type=''):\n",
    "    from pipeUtils import Annotation\n",
    "    from pipeUtils import Document\n",
    "\n",
    "    #ann_obj=Annotation()\n",
    "    Annotations1=[]\n",
    "    for index, row in df.iterrows() :\n",
    "\n",
    "        if (pdoc_type == row['type'] or ndoc_type == row['type']):\n",
    "            continue\n",
    "        ann_obj=Annotation(start_index=row['start'], end_index=row['end'], type=row['type'], spanned_text=row['txt'], ann_id=row['markup_id'])\n",
    "        Annotations1.append(ann_obj)\n",
    "\n",
    "    return Annotations1\n",
    "\n",
    "###############################################################################################\n",
    "\n",
    "def compare2ann_types_by_span(ref_ann=[], sys_ann=[], ref_type ='Annotation', sys_type='Annotation', exact=True):\n",
    "    tp, fp, fn = 0,0,0\n",
    "    tp_list = []\n",
    "    fp_list = []\n",
    "    fn_list = []\n",
    "    ref_anns = []\n",
    "    sys_anns = []\n",
    "\n",
    "    # Split annotations of different types into two lists\n",
    "    for a in ref_ann:\n",
    "        if(a.type == ref_type):\n",
    "            ref_anns.append(a)\n",
    "    for a in sys_ann:\n",
    "        if(a.type == sys_type):\n",
    "            sys_anns.append(a)\n",
    "\n",
    "    # Count tp and fp\n",
    "    for sys_ann in sys_anns:\n",
    "        tp_flag = False\n",
    "        matching_ref = None\n",
    "        for ref_ann in ref_anns:\n",
    "            if exact:\n",
    "                if(sys_ann.exactMatch(ref_ann)):\n",
    "                    tp_flag=True\n",
    "                    matching_ref = ref_ann\n",
    "            else:\n",
    "                if sys_ann.overlaps(ref_ann):\n",
    "                    tp_flag = True\n",
    "                    matching_ref = ref_ann\n",
    "        if tp_flag:\n",
    "            tp = tp + 1\n",
    "            tp_list.append([sys_ann, matching_ref])\n",
    "        else:\n",
    "            fp = fp + 1\n",
    "            fp_list.append(sys_ann)\n",
    "\n",
    "    # Count fn\n",
    "    for ref_ann in ref_anns:\n",
    "        tp_flag = False\n",
    "        for sys_ann in sys_anns:\n",
    "            if exact:\n",
    "                if(ref_ann.exactMatch(sys_ann)):\n",
    "                    tp_flag=True\n",
    "            else:\n",
    "                if ref_ann.overlaps(sys_ann):\n",
    "                    tp_flag = True\n",
    "        if not tp_flag:\n",
    "            fn = fn + 1\n",
    "            fn_list.append(ref_ann)\n",
    "\n",
    "    return tp, fp, fn, tp_list, fp_list, fn_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert d-dimer nlp to annotation obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLP_0 high_ddimer 398 414 elevated d-dimer\n",
      "NLP_1 high_ddimer 2023 2039 elevated d-dimer\n"
     ]
    }
   ],
   "source": [
    "Annotations2=df2ann(df=nlp_df, pdoc_type='positive_DOC', ndoc_type='negative_DOC')\n",
    "for a in Annotations2:\n",
    "    print (a.ann_id, a.type, a.start_index, a.end_index, a.spanned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read manual ref_ann and convert to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "unid = 'u0496358'\n",
    "path = \"/home/\"+str(unid)+\"/BRAT/\"+str(unid)+\"/Project_pe_test\" \n",
    "\n",
    "ann_file='90688_292.ann'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>markup_id</th>\n",
       "      <th>type</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>High_Ddimer</td>\n",
       "      <td>398</td>\n",
       "      <td>414</td>\n",
       "      <td>elevated D-dimer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2</td>\n",
       "      <td>High_Ddimer</td>\n",
       "      <td>2023</td>\n",
       "      <td>2039</td>\n",
       "      <td>elevated D-dimer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3</td>\n",
       "      <td>PE</td>\n",
       "      <td>154</td>\n",
       "      <td>156</td>\n",
       "      <td>PE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T4</td>\n",
       "      <td>PE</td>\n",
       "      <td>459</td>\n",
       "      <td>461</td>\n",
       "      <td>PE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T5</td>\n",
       "      <td>PE</td>\n",
       "      <td>688</td>\n",
       "      <td>690</td>\n",
       "      <td>PE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T6</td>\n",
       "      <td>PE</td>\n",
       "      <td>3154</td>\n",
       "      <td>3156</td>\n",
       "      <td>PE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>T7</td>\n",
       "      <td>PE</td>\n",
       "      <td>653</td>\n",
       "      <td>655</td>\n",
       "      <td>PE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T8</td>\n",
       "      <td>PE</td>\n",
       "      <td>6332</td>\n",
       "      <td>6334</td>\n",
       "      <td>PE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>T9</td>\n",
       "      <td>PE</td>\n",
       "      <td>929</td>\n",
       "      <td>947</td>\n",
       "      <td>pulmonary embolism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>T11</td>\n",
       "      <td>PE</td>\n",
       "      <td>4648</td>\n",
       "      <td>4666</td>\n",
       "      <td>pulmonary embolism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>T12</td>\n",
       "      <td>PE</td>\n",
       "      <td>5671</td>\n",
       "      <td>5689</td>\n",
       "      <td>pulmonary embolism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>T10</td>\n",
       "      <td>PE</td>\n",
       "      <td>3777</td>\n",
       "      <td>3795</td>\n",
       "      <td>pulmonary embolism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>T13</td>\n",
       "      <td>PE</td>\n",
       "      <td>2051</td>\n",
       "      <td>2068</td>\n",
       "      <td>pulmonary embolus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>T14</td>\n",
       "      <td>PE</td>\n",
       "      <td>3968</td>\n",
       "      <td>3985</td>\n",
       "      <td>pulmonary embolus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>T15</td>\n",
       "      <td>positive_DOC</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   markup_id          type start   end                 txt\n",
       "0         T1   High_Ddimer   398   414    elevated D-dimer\n",
       "1         T2   High_Ddimer  2023  2039    elevated D-dimer\n",
       "2         T3            PE   154   156                  PE\n",
       "3         T4            PE   459   461                  PE\n",
       "4         T5            PE   688   690                  PE\n",
       "5         T6            PE  3154  3156                  PE\n",
       "6         T7            PE   653   655                  PE\n",
       "7         T8            PE  6332  6334                  PE\n",
       "8         T9            PE   929   947  pulmonary embolism\n",
       "9        T11            PE  4648  4666  pulmonary embolism\n",
       "10       T12            PE  5671  5689  pulmonary embolism\n",
       "11       T10            PE  3777  3795  pulmonary embolism\n",
       "12       T13            PE  2051  2068   pulmonary embolus\n",
       "13       T14            PE  3968  3985   pulmonary embolus\n",
       "14       T15  positive_DOC     0     1                   ["
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read ann and convert to df\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "annoList = []\n",
    "\n",
    "with open(os.path.join(path,ann_file)) as f:\n",
    "    ann_file = f.read()\n",
    "ann_file=ann_file.split('\\n')\n",
    "\n",
    "for line in ann_file:\n",
    "\n",
    "    if(line.startswith('T')):\n",
    "        line=line.replace('\\n', '')\n",
    "        line=line.split('\\t')\n",
    "\n",
    "        line0=line[0]\n",
    "        line2=line[2]\n",
    "        line1=line[1].split(' ')\n",
    "        \n",
    "        if (';' in line1[2]):\n",
    "            line1.remove(line1[2])   # remove middle span of annotated phrase seprated in 2 line, keep the annotation.\n",
    "                        \n",
    "        annList = []\n",
    "        annList.append(line[0])\n",
    "        annList.extend(line1)\n",
    "        annList.append(line[2])\n",
    "        annoList.append(annList)\n",
    "#print(annoList)  \n",
    "    \n",
    "ann_df = pd.DataFrame(annoList, columns=['markup_id','type','start','end','txt'])    \n",
    "ann_df\n",
    "#ann_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert manual ref_ann df to annotation obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLP_0 high_ddimer 398 414 elevated d-dimer\n",
      "NLP_1 high_ddimer 2023 2039 elevated d-dimer\n"
     ]
    }
   ],
   "source": [
    "Annotations3=df2ann(ann_df, pdoc_type='positive_DOC', ndoc_type='negative_DOC')\n",
    "for a in Annotations2:\n",
    "    print (a.ann_id, a.type, a.start_index, a.end_index, a.spanned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mention Level Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp, fp, fn\n",
      "0 0 2\n",
      "-----fn_list-----\n",
      "NLP_0 398 414\n",
      "NLP_1 2023 2039\n"
     ]
    }
   ],
   "source": [
    "tp, fp, fn, tp_list, fp_list, fn_list = compare2ann_types_by_span(ref_ann=Annotations2, sys_ann=Annotations3, ref_type ='high_ddimer', sys_type='high_ddimer', exact=True)\n",
    "print(\"tp, fp, fn\")\n",
    "print(tp, fp, fn)\n",
    "print(\"-----fn_list-----\")\n",
    "for i in fn_list:\n",
    "    print(i.ann_id, i.start_index, i.end_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
